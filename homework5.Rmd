---
title: "Homework5"
author: "Yunjia Liu"
date: "2024-11-13"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(rvest)
library(ggplot2)
library(dplyr)
set.seed(1)
```

## Problem 1
Generate a birthday simulation, which generates random birthdays and checks for duplicates.
```{r}
bday_simulation = function(group_size){
  birthdays <- sample(1:365, group_size, replace = TRUE)
  return(any(duplicated(birthdays)))
}
```

Initialize the group_size and number of simulations.
```{r}
group_sizes <- 2:50
n_simulations <- 10000
probabilities <- numeric(length(group_sizes))
```
Run simulation. \
Perform simulations for the current group size using map_lgl. mean(results) calculates the probability of at least one shared birthday for group_size = i.\

```{r}
for (i in 1:length(group_sizes)) {
  group_size = group_sizes[i]
  results = map_lgl(1:n_simulations, ~bday_simulation(group_size))
  probabilities[i] = mean(results)
}
output_df = tibble(
  group_size = group_sizes,
  probability = probabilities
  )
```

Plot the probabilities.\

```{r}
ggplot(output_df, aes(x = group_size, y = probability)) +
  geom_line() +
  geom_point() +
  labs(
    title = "Probability of Shared Birthday vs. Group Size",
    x = "Group Size",
    y = "Probability of Duplicate Birthdays"
  ) +
  theme_minimal()

```
The plot showcases the counterintuitive nature of the problem: even with a seemingly small group (23 people), there is a high chance of at least one shared birthday.
The curve's steep growth between group sizes 10 and 30 highlights how quickly the probability increases in that range.

## Problem 2

```{r}
n = 30
sigma = 5
alpha = 0.05
mu_values = 0:6
n_simulations <- 5000
```

Function for every mu values: \
Generate data from N(mu, sigma) and perform a one-sample t-test. After that, we use broom::tidy() function to extract estimate and p-value
```{r}
simulate_t_test <- function(n, mu, sigma, alpha) {
  data <- rnorm(n, mean = mu, sd = sigma)

  t_test_result = t.test(data, mu = 0)
  
  tidy_result = broom::tidy(t_test_result)
  estimate = tidy_result$estimate
  p_value = tidy_result$p.value
  reject_null = p_value < alpha
  
  tibble(
    u_hat = estimate, 
    p_value = p_value,
    reject_null = reject_null
  )

}
```


```{r}
sim_results_df = 
  expand_grid(
    sample_size = n,
    mu = 1:6,
    iter = 1:n_simulations,
  ) |> 
  mutate(
    estimate_df = map(mu, ~simulate_t_test(n, .x, sigma,alpha))
  ) |> 
  unnest(estimate_df)
```

```{r}
summary_results <- sim_results_df %>%
  group_by(mu) %>%
  summarise(
    power = mean(reject_null),                      # Proportion of null rejected
    avg_u_hat = mean(u_hat),                        # Average estimate
    avg_u_hat_rejected = mean(u_hat[reject_null])   # Average estimate when null is rejected
  )
```


```{r}
# Plot: Power vs True Value of Mu
ggplot(summary_results, aes(x = mu, y = power)) +
  geom_line(color = "blue") +
  geom_point(color = "blue") +
  labs(
    title = "Power vs True Value of Mu",
    x = "True Value of Mu",
    y = "Power (Proportion of Null Rejected)"
  ) +
  theme_minimal()
```


```{r}
# Plot: Average Estimate vs True Value of Mu
ggplot(summary_results, aes(x = mu)) +
  geom_line(aes(y = avg_u_hat, color = "All Estimates")) +
  geom_line(aes(y = avg_u_hat_rejected, color = "Rejected Null")) +
  geom_point(aes(y = avg_u_hat, color = "All Estimates")) +
  geom_point(aes(y = avg_u_hat_rejected, color = "Rejected Null")) +
  labs(
    title = "Average Estimate of Mu vs True Value of Mu",
    x = "True Value of Mu",
    y = "Average Estimate of Mu",
    color = "Legend"
  ) +
  theme_minimal()

```

